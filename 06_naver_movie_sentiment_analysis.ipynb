{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 영화 리플 크롤링 및 감성분석\n",
    "\n",
    "### Naver Movie Reple Crawling and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 네이버 영화 크롤링 (별점,리플 -> 영화 제목별 파일)\n",
    "\n",
    "#### step 1. Crawling ( score, reple -> .csv file )\n",
    "#### start url : https://movie.naver.com/movie/running/current.nhn?order=reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : url\n",
    "# return: bs4.BeautifulSoup\n",
    "def requestPage(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    return soup\n",
    "\n",
    "# input : url\n",
    "# return: movie code\n",
    "def getMovieCode(url) :\n",
    "    soup = requestPage(url)\n",
    "    a_list = soup.select('ul.lst_detail_t1 > li > div.thumb > a')\n",
    "    code_list = []\n",
    "    for a_tag in a_list:\n",
    "        href = a_tag.attrs['href'].strip()\n",
    "        code = href.split('=')[1]\n",
    "        code_list.append(code)\n",
    "    return code_list\n",
    "\n",
    "# input : url\n",
    "# return: movie name\n",
    "def getMovieName(url) :\n",
    "    soup = requestPage(url)\n",
    "    a_list = soup.select('ul.lst_detail_t1 > li > dl.lst_dsc > dt.tit > a')\n",
    "    name_list = []\n",
    "    for a_tag in a_list:\n",
    "        name = a_tag.text.strip()\n",
    "        name = name.replace(':','')\n",
    "        name_list.append(name)\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : soup\n",
    "# return: (score, reple) in a page\n",
    "def onePageData(soup):\n",
    "    div_result_tag = soup.select('div.score_result')\n",
    "    star_score_list = []\n",
    "    reple_list = []\n",
    "    for tag in div_result_tag:\n",
    "        star_score_list += tag.select('div.star_score > em')\n",
    "        reple_list += tag.select('div.score_reple > p')\n",
    "    result = []\n",
    "    for i in range(len(star_score_list)):\n",
    "        a_score = star_score_list[i].text\n",
    "        a_reple = reple_list[i].text\n",
    "        a_tuple = (a_score,a_reple)\n",
    "        result.append(a_tuple)\n",
    "    return result\n",
    "\n",
    "# input : movie_code\n",
    "# output: total reple_pages of movie\n",
    "def getPageCnt(movie_code):\n",
    "    url = f'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code={movie_code}&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=1'\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    total_score = soup.select('div.score_total > strong.total > em')[0].text\n",
    "    # print(soup.select('div.score_total > strong.total > em')[0].prettify())\n",
    "    total_score = total_score.replace(',','')\n",
    "    page = int(total_score) // 10\n",
    "    if ( int(total_score) % 10) != 0:\n",
    "        page += 1\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd # 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get movie Code and Name\n",
    "url = 'https://movie.naver.com/movie/running/current.nhn?order=reserve'\n",
    "movie_list = getMovieCode(url)\n",
    "file_list = getMovieName(url)\n",
    "n_movies = len(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "돈 : 55 reple pages\n",
      "캡틴 마블 : 3022 reple pages\n",
      "우상 : 24 reple pages\n",
      "악질경찰 : 19 reple pages\n",
      "이스케이프 룸 : 143 reple pages\n",
      "라스트 미션 : 44 reple pages\n",
      "그린 북 : 451 reple pages\n",
      "더 페이버릿 여왕의 여자 : 150 reple pages\n",
      "아사코 : 21 reple pages\n",
      "극한직업 : 4448 reple pages\n",
      "살인마 잭의 집 : 35 reple pages\n",
      "더 와이프 : 24 reple pages\n",
      "숲속왕국의 꿀벌 여왕 : 5 reple pages\n",
      "항거유관순 이야기 : 636 reple pages\n",
      "철벽선생 : 12 reple pages\n",
      "가버나움 : 236 reple pages\n",
      "증인 : 1015 reple pages\n",
      "1919 유관순 : 22 reple pages\n",
      "그때 그들 : 4 reple pages\n",
      "칠곡 가시나들 : 33 reple pages\n",
      "국경의 왕 : 6 reple pages\n",
      "에브리타임 룩 앳 유 : 3 reple pages\n",
      "콜드 워 : 27 reple pages\n",
      "나는 다른 언어로 꿈을 꾼다 : 4 reple pages\n",
      "킹 오브 프리즘 -샤이니 세븐 스타즈- : 6 reple pages\n",
      "사바하 : 1168 reple pages\n",
      "로마 : 193 reple pages\n",
      "일일시호일 : 75 reple pages\n",
      "리노 : 7 reple pages\n",
      "러브 라이브! 선샤인!! 더 스쿨 아이돌 무비 오버 더 레인보우 : 27 reple pages\n",
      "보헤미안 랩소디 : 3858 reple pages\n",
      "빠삐용 : 25 reple pages\n",
      "도쿄의 밤하늘은 항상 가장 짙은 블루 : 22 reple pages\n",
      "히치하이크 : 2 reple pages\n",
      "신데렐라마법 반지의 비밀 : 92 reple pages\n",
      "님포매니악 볼륨2 : 38 reple pages\n",
      "내가 사는 세상 : 4 reple pages\n",
      "님포매니악 볼륨1 : 46 reple pages\n",
      "인생 후르츠 : 107 reple pages\n",
      "엔젤페이스 : 2 reple pages\n",
      "드래곤 길들이기 3 : 357 reple pages\n",
      "얼굴들 : 3 reple pages\n",
      "아라비아의 로렌스 : 20 reple pages\n",
      "환절기 : 30 reple pages\n",
      "슈퍼미니 2 : 10 reple pages\n",
      "페이트 스테이 나이트 헤븐즈필 제1장 프레시지 플라워 : 82 reple pages\n",
      "질투의 역사 : 5 reple pages\n",
      "포항 : 2 reple pages\n",
      "브라더 오브 더 이어 : 6 reple pages\n",
      "극장판 헬로카봇옴파로스 섬의 비밀 : 199 reple pages\n",
      "이월 : 5 reple pages\n",
      "콜드 체이싱 : 68 reple pages\n",
      "두 번째 겨울 : 3 reple pages\n",
      "러빙 빈센트 : 561 reple pages\n",
      "마피아 : 2 reple pages\n",
      "봄은 온다 : 1 reple pages\n",
      "시인 할매 : 13 reple pages\n",
      "퍼미션 : 3 reple pages\n",
      "1991, 봄 : 8 reple pages\n",
      "극장판 공룡메카드 타이니소어의 섬 : 3 reple pages\n",
      "다영씨 : 36 reple pages\n",
      "델타 보이즈 : 144 reple pages\n",
      "도화선 : 2 reple pages\n",
      "딥 : 144 reple pages\n",
      "메리 포핀스 리턴즈 : 13 reple pages\n",
      "메이트 : 38 reple pages\n",
      "바르다가 사랑한 얼굴들 : 1 reple pages\n",
      "뱀파이어 : 3 reple pages\n",
      "빌리어네어 보이즈클럽 : 18 reple pages\n",
      "산딸기 2 : 414 reple pages\n",
      "산상수훈 : 38 reple pages\n",
      "색, 계 : 2 reple pages\n",
      "쇠파리 : 136 reple pages\n",
      "악인이여 지옥행 급행열차를 타라 : 85 reple pages\n",
      "언더독 : 89 reple pages\n",
      "엽문3 최후의 대결 : 13 reple pages\n",
      "용호문 : 653 reple pages\n",
      "위대한 레보스키 : 2 reple pages\n",
      "자전차왕 엄복동 : 771 reple pages\n",
      "저개발의 기억 : 44 reple pages\n",
      "정글북 : 323 reple pages\n",
      "펀치 드렁크 러브 : 3 reple pages\n",
      "플립 : 2 reple pages\n",
      "허비 행콕  무한한 가능성 : 24 reple pages\n",
      "험악한 꿈 : 1 reple pages\n",
      "미스 사이공 25주년 특별 공연 : 21 reple pages\n",
      "상류시대 : 1 reple pages\n",
      "송곳니 : 1 reple pages\n"
     ]
    }
   ],
   "source": [
    "# save each movie_name.csv files \n",
    "for idx in range(n_movies):\n",
    "    pages = getPageCnt(movie_list[idx])\n",
    "    print( f'{file_list[idx]} : {pages} reple pages')\n",
    "    save_file = f'./movie_reples/{file_list[idx]}.csv'\n",
    "    \n",
    "    for i in range(pages):\n",
    "        if (i%20 == 0): time.sleep(1)\n",
    "        #if (i == 5) : break  # 페이지 수 제한\n",
    "        \n",
    "        site = f'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code={movie_list[idx]}&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page={i+1}'\n",
    "        soup = requestPage(site)\n",
    "        data = onePageData(soup)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        if i == 0:\n",
    "            df.columns = ['score', 'reple']\n",
    "            df.to_csv(save_file, index=False, encoding='utf-8-sig')\n",
    "        else:\n",
    "            df.to_csv(save_file, header=False, \n",
    "                      index=False, mode='a', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 크롤링 데이터 통합\n",
    "\n",
    "#### step 2. Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of saved files\n",
    "read_file_list = os.listdir('./movie_reples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_file = len(read_file_list)\n",
    "save_file = './movie_total_reples.csv'\n",
    "for i in range(n_file):\n",
    "    file_name = f'./movie_reples/{read_file_list[i]}'\n",
    "    data = pd.read_csv(file_name)\n",
    "    if i == 0:\n",
    "        data.to_csv(save_file, index=False, encoding='utf-8-sig')\n",
    "    else:\n",
    "        data.to_csv(save_file, header=False, \n",
    "                  index=False, mode='a', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 수집된 평점으로 감성분석\n",
    "\n",
    "#### step 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from konlpy.tag import *  \n",
    "# pip install konlpy 에러 시 Visual Studio 설치(Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./movie_total_reples.csv')\n",
    "#df.head(5)\n",
    "\n",
    "# 전처리\n",
    "def text_preprocessing(text):\n",
    "    if text.startswith('관람객'):\n",
    "        text = text[3:]\n",
    "    return text\n",
    "def score_preprocessing(text):\n",
    "    value = int(text)\n",
    "    if value <= 5 :\n",
    "        return '0'\n",
    "    else:\n",
    "        return '1'\n",
    "# 문자열마다 함수 호출\n",
    "df['reple'] = df['reple'].apply(text_preprocessing) \n",
    "df['score'] = df['score'].apply(score_preprocessing) \n",
    "df.to_csv('./movie_total_reples_pre.csv', index=False, encoding='utf-8-sig')\n",
    "print('전처리 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split\n",
    "df = pd.read_csv('./movie_total_reples_pre.csv')\n",
    "score_list = df['score'].tolist()\n",
    "reple_list = df['reple'].tolist()\n",
    "\n",
    "reple_train, reple_test, score_train, score_test \\\n",
    "    = train_test_split(reple_list, score_list, test_size=0.3)\n",
    "\n",
    "# train, test to files\n",
    "dic_train = {\n",
    "    'score' : score_train,\n",
    "    'reple' : reple_train\n",
    "}\n",
    "dic_test = {\n",
    "    'score' : score_test,\n",
    "    'reple' : reple_test\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(dic_train)\n",
    "df_test = pd.DataFrame(dic_test)\n",
    "\n",
    "df_train.to_csv('train.csv', index=False, encoding='utf-8-sig')\n",
    "df_test.to_csv('test.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJH\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n",
      "time : 242.42454600334167\n",
      "정확도 : 0.917950555356503\n",
      "save complete\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "X_train = train_df['reple'].tolist()\n",
    "y_train = train_df['score'].tolist()\n",
    "X_test = test_df['reple'].tolist()\n",
    "y_test = test_df['score'].tolist()\n",
    "\n",
    "# 모델 객체 생성\n",
    "okt = Okt()  # 트위터가 제공하는 형태소 분석기\n",
    "def text_tokenizer(text):\n",
    "    return okt.morphs(text)\n",
    "\n",
    "# 단어 사전 구축\n",
    "word_mod = TfidfVectorizer(lowercase=False, tokenizer=text_tokenizer)\n",
    "# L2 정규식 적용한 분류 모델\n",
    "class_mod = LogisticRegression(C=10.0, penalty='l2')\n",
    "# 파이프라인 구축\n",
    "pipe = Pipeline([('vect',word_mod),('clf',class_mod)] )\n",
    "\n",
    "# 학습\n",
    "import time\n",
    "start_time = time.time()\n",
    "print('start')\n",
    "pipe.fit(X_train, y_train)\n",
    "print('end')\n",
    "end_time = time.time()\n",
    "print(f'time : {end_time - start_time}')\n",
    "\n",
    "# 모델 저장\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(f'정확도 : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "with open('pipe.dat', 'wb') as fp:\n",
    "    pickle.dump(pipe, fp)\n",
    "print('save complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 작성 : 재미있어요\n",
      "긍정적\n",
      "정확도 : 99.85337898382643\n"
     ]
    }
   ],
   "source": [
    "# 저장한 모델 활용\n",
    "import pickle\n",
    "import numpy as np\n",
    "from konlpy.tag import * \n",
    "\n",
    "def text_tokenizer(text):\n",
    "    okt = Okt()\n",
    "    return okt.morphs(text)\n",
    "\n",
    "with open('pipe.dat', 'rb')as fp:\n",
    "    pipe = pickle.load(fp)\n",
    "    \n",
    "text = input('리뷰 작성 : ')\n",
    "str1 = [text]\n",
    "\n",
    "r1 = np.max(pipe.predict_proba(str1) * 100)\n",
    "r2 = pipe.predict(str1)[0]\n",
    "\n",
    "if r2 == 1:\n",
    "    print('긍정적')\n",
    "else:\n",
    "    print('부정적')\n",
    "print(f'정확도 : {r1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
